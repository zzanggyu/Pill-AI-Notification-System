"""
ì•Œì•½ ì¸ì‹ ì„œë²„ (Model Server)
- YOLOë¥¼ ì´ìš©í•œ ì•Œì•½ ê²€ì¶œ
- OCRì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ì¸ì‹
- VGG16ì„ ì´ìš©í•œ ëª¨ì–‘ ë¶„ë¥˜
- ìƒ‰ìƒ ê·¸ë£¹ ë¶„ë¥˜
ì‘ì„±ì: [ê¹€í˜„ê·œ]
ë§ˆì§€ë§‰ ìˆ˜ì •: 2024-10-27
"""

###################
# Library Imports #
###################

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import time
import re
import base64
import traceback
from functools import wraps

# ì›¹ ì„œë²„ ê´€ë ¨
from flask import Flask, request, jsonify
from flask_cors import CORS

# ì´ë¯¸ì§€ ì²˜ë¦¬
import cv2
import numpy as np
from PIL import Image

# ë”¥ëŸ¬ë‹ ê´€ë ¨
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from ultralytics import YOLO
import easyocr

# ë°ì´í„° ë¶„ì„
from sklearn.mixture import GaussianMixture

# ë¡œê¹…
import logging

#################
# Configuration #
#################

# ì„œë²„ ì„¤ì •
PUBLIC_IP = "121.132.196.27"
MODEL_SERVER_PORT = 5000

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
MODEL_BASE_PATH = 'G:/ë‚´ ë“œë¼ì´ë¸Œ/ìº¡ìŠ¤í†¤ ë””ìì¸ ìµœì¢…ë³¸'
YOLO_MODEL_PATH = f'{MODEL_BASE_PATH}/Yolov8n/weights/best.pt'
VGG_MODEL_PATH = f'{MODEL_BASE_PATH}/vgg/pill_shape_classifier_3class_best.pth'
OCR_MODEL_PATH = f'{MODEL_BASE_PATH}/Easy'

# ë¡œê¹… ì„¤ì •
class CustomFormatter(logging.Formatter):
    """ì»¤ìŠ¤í…€ ë¡œê·¸ í¬ë§·í„°"""
    
    # ANSI ìƒ‰ìƒ ì½”ë“œ
    grey = "\x1b[38;21m"
    blue = "\x1b[38;5;39m"
    yellow = "\x1b[38;5;226m"
    red = "\x1b[38;5;196m"
    reset = "\x1b[0m"

    def __init__(self):
        super().__init__()
        self.fmt = "%(asctime)s [%(levelname)s]: %(message)s"
        self.datefmt = "%H:%M:%S"

    def format(self, record):
        # ë¡œê·¸ ë ˆë²¨ë³„ ìƒ‰ìƒ ì§€ì •
        color = self.blue  # ê¸°ë³¸ ìƒ‰ìƒ
        
        if record.levelno == logging.WARNING:
            color = self.yellow
        elif record.levelno == logging.ERROR:
            color = self.red
            
        # ë©”ì‹œì§€ì— ìƒ‰ìƒ ì ìš©
        formatter = logging.Formatter(
            f"{color}{self.fmt}{self.reset}",
            self.datefmt
        )
        
        return formatter.format(record)

def setup_logging():
    """ë¡œê¹… ì„¤ì •ì„ ì´ˆê¸°í™”"""
    logger = logging.getLogger(__name__)
    if logger.hasHandlers():
        logger.handlers.clear()
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì •    
    logger.setLevel(logging.INFO)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(CustomFormatter())
    logger.addHandler(console_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler('pill_server.log')
    file_handler.setFormatter(
        logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            '%Y-%m-%d %H:%M:%S'
        )
    )
    logger.addHandler(file_handler)
    
    # ë¡œê±° ì „íŒŒ ë°©ì§€
    logger.propagate = False
    
    return logger

# ë¡œê±° ì´ˆê¸°í™”
logger = setup_logging()

####################
# Flask ì•± ì´ˆê¸°í™” #
####################

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

def log_request_response(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        # ìš”ì²­ ë¡œê¹…
        logger.info("\n" + "="*50)
        logger.info("API ìš”ì²­")
        logger.info("-"*30)
        
        if request.method == 'POST':
            if 'image' in request.json:
                image_size = len(request.json['image'])
                logger.info(f"- ì´ë¯¸ì§€ í¬ê¸°: {image_size:,} bytes")
        
        # í•¨ìˆ˜ ì‹¤í–‰
        response = func(*args, **kwargs)
        
        # ì‘ë‹µ ë¡œê¹…
        if isinstance(response, tuple):
            response_data, status_code = response
        else:
            response_data, status_code = response, 200
            
        processing_time = time.time() - start_time
        
        logger.info("\nAPI ì‘ë‹µ")
        logger.info("-"*30)
        logger.info(f"- ìƒíƒœ ì½”ë“œ: {status_code}")
        logger.info(f"- ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        
        if isinstance(response_data, dict):
            if 'error' in response_data:
                logger.error(f"â€¢ ì˜¤ë¥˜: {response_data['error']}")
                
        logger.info("="*50 + "\n")
        return response
        
    return wrapper

####################
# Shape Classifier #
####################

class ShapeClassifier:
    """
    ì•Œì•½ ëª¨ì–‘ ë¶„ë¥˜ê¸°
    - VGG16 ê¸°ë°˜ ë¶„ë¥˜ê¸°
    - 3ê°€ì§€ í´ë˜ìŠ¤: ì›í˜•, ì¥ë°©í˜•, íƒ€ì›í˜•
    - ImageNet ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì‚¬ìš©
    """
    
    def __init__(self, vgg_model_path):
        """
        ëª¨ë¸ ì´ˆê¸°í™”
        Args:
            vgg_model_path (str): VGG ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
        """
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        logger.info(f"Shape Classifierë¥¼ {self.device} ì¥ì¹˜ì—ì„œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")

        # í´ë˜ìŠ¤ ì •ì˜ (ë¨¼ì € ì •ì˜)
        self.shape_classes = ["ì›í˜•", "ì¥ë°©í˜•", "íƒ€ì›í˜•"]

        # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ (shape_classes ì •ì˜ í›„ì— í˜¸ì¶œ)
        self.model = self.create_vgg_model()
        checkpoint = torch.load(vgg_model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        self.model = self.model.to(self.device)

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì •ì˜
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),  # VGG16 ì…ë ¥ í¬ê¸°
            transforms.ToTensor(),
            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
        logger.info("Shape Classifier ì´ˆê¸°í™” ì™„ë£Œ")

        

        
    def create_vgg_model(self):
        """
        VGG16 ëª¨ë¸ ìƒì„± ë° ìˆ˜ì •
        Returns:
            nn.Module: ìˆ˜ì •ëœ VGG16 ëª¨ë¸
        """
        # ImageNet ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™”ëœ VGG16 ëª¨ë¸ ë¡œë“œ
        model = models.vgg16(weights='IMAGENET1K_V1')
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ 3ê°œ í´ë˜ìŠ¤ë¡œ ìˆ˜ì •
        model.classifier[6] = nn.Linear(4096, len(self.shape_classes))
        
        return model
    
    def predict_shape(self, image):
        """
        ì´ë¯¸ì§€ì—ì„œ ì•Œì•½ ëª¨ì–‘ ì˜ˆì¸¡
        Args:
            image (numpy.ndarray or PIL.Image): ì…ë ¥ ì´ë¯¸ì§€
            
        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼ì™€ ê° í´ë˜ìŠ¤ë³„ í™•ë¥ 
        """
        try:
            # ì´ë¯¸ì§€ í˜•ì‹ ë³€í™˜
            if isinstance(image, np.ndarray):
                image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            elif not isinstance(image, Image.Image):
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤.")
            
            # ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(image_tensor)
                _, predicted = torch.max(outputs, 1)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            result = {
                'predicted_class': self.shape_classes[predicted.item()],
                'probabilities': {
                    self.shape_classes[i]: prob.item()
                    for i, prob in enumerate(probabilities)
                }
            }
            
            # ë¡œê¹…
            logger.info("\nëª¨ì–‘ ë¶„ë¥˜ ê²°ê³¼:")
            logger.info(f"- ì˜ˆì¸¡ëœ ëª¨ì–‘: {result['predicted_class']}")  # â€¢ -> -
            logger.info("- í´ë˜ìŠ¤ë³„ í™•ë¥ :")  # â€¢ -> -
            for shape, prob in result['probabilities'].items():
                logger.info(f"  - {shape}: {prob:.2%}")

            return result
            
        except Exception as e:
            logger.error(f"ëª¨ì–‘ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
#########################
# Pill Recognition Model #
#########################

class PillRecognitionModel:
    """
    ì•Œì•½ ì¸ì‹ì„ ìœ„í•œ í†µí•© ëª¨ë¸ í´ë˜ìŠ¤
    - YOLO: ì•Œì•½ ê²€ì¶œ
    - EasyOCR: í…ìŠ¤íŠ¸ ì¸ì‹
    - VGG16: ëª¨ì–‘ ë¶„ë¥˜
    - GMM: ìƒ‰ìƒ êµ°ì§‘í™”
    """
    
    def __init__(self):
        """ëª¨ë¸ ì´ˆê¸°í™” ë° ì„¤ì •"""
        logger.info("\nì•Œì•½ ì¸ì‹ ëª¨ë¸ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        self.yolo_model = self.load_yolo_model()
        
        # OCR ì´ˆê¸°í™”
        self.ocr_reader = easyocr.Reader(
            ['en'],  # ì˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì¸ì‹
            model_storage_directory=OCR_MODEL_PATH,
            recog_network='english_g2'  # ì •í™•ë„ ë†’ì€ ë²„ì „ ì‚¬ìš©
        )
        
        # ëª¨ì–‘ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        self.shape_classifier = ShapeClassifier(VGG_MODEL_PATH)
        
        # ìƒ‰ìƒ ê·¸ë£¹ ì •ì˜
        self.color_groups = {
            'í•˜ì–‘': [
                ('í•˜ì–‘', (210, 210, 210)), 
                ('í•˜ì–‘', (220, 220, 220)),
                ('í•˜ì–‘', (144, 144, 149)),
                ('í•˜ì–‘', (240, 240, 240))
            ],
            'ê²€ì •': [
                ('ê²€ì •', (0, 0, 0)), 
                ('ê²€ì •', (20, 20, 20))
            ],
            'íšŒìƒ‰': [
                ('íšŒìƒ‰', (80, 80, 80))
            ],
            'ë…¸ë‘/ì£¼í™©/ë¶„í™/ë¹¨ê°•/ê°ˆìƒ‰': [
                ('ë…¸ë‘', (255, 255, 0)),
                ('ë…¸ë‘', (255, 255, 100)),
                ('ë…¸ë‘', (178, 178, 170)),
                ('ì£¼í™©', (255, 165, 0)),
                ('ì£¼í™©', (255, 140, 0)),
                ('ë¶„í™', (255, 192, 203)),
                ('ë¶„í™', (255, 182, 193)),
                ('ë¹¨ê°•', (255, 0, 0)),
                ('ë¹¨ê°•', (220, 20, 60)),
                ('ê°ˆìƒ‰', (139, 69, 19))
            ],
            'ì—°ë‘/ì´ˆë¡/ì²­ë¡': [
                ('ì—°ë‘', (154, 205, 50)),
                ('ì—°ë‘', (124, 252, 0)),
                ('ì´ˆë¡', (34, 139, 34)),
                ('ì´ˆë¡', (60, 150, 60)),
                ('ì²­ë¡', (0, 255, 255))
            ],
            'íŒŒë‘/ë‚¨ìƒ‰': [
                ('íŒŒë‘', (0, 0, 255)),
                ('íŒŒë‘', (30, 144, 255)),
                ('íŒŒë‘', (201, 227, 236)),
                ('ë‚¨ìƒ‰', (0, 0, 128))
            ],
            'ìì£¼/ë³´ë¼': [
                ('ìì£¼', (255, 0, 255)),
                ('ìì£¼', (218, 112, 214)),
                ('ë³´ë¼', (128, 0, 128))
            ]
        }
        
        logger.info("ì•Œì•½ ì¸ì‹ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def load_yolo_model(self):
        """YOLO ëª¨ë¸ ë¡œë“œ"""
        try:
            if not os.path.exists(YOLO_MODEL_PATH):
                raise FileNotFoundError(f"YOLO ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {YOLO_MODEL_PATH}")
            
            model = YOLO(YOLO_MODEL_PATH)
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            model.to(device)
            
            logger.info(f"YOLO ëª¨ë¸ì„ {device} ì¥ì¹˜ì— ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return model
            
        except Exception as e:
            logger.error(f"YOLO ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    def log_pill_features(self, text, color_info, shape_info):
        """
        ì•Œì•½ì˜ ì¶”ì¶œëœ íŠ¹ì„±ì„ ë¡œê¹…

        Args:
            text (list): ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            color_info (tuple): (RGBê°’, (ìƒ‰ìƒê·¸ë£¹, êµ¬ì²´ìƒ‰ìƒ)) í˜•íƒœì˜ íŠœí”Œ
            shape_info (dict): ëª¨ì–‘ ë¶„ë¥˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("\n" + "="*50)
        logger.info("ì•Œì•½ íŠ¹ì„± ë¶„ì„ ê²°ê³¼")
        logger.info("-"*30)

        # í…ìŠ¤íŠ¸ ì •ë³´
        if text:
            logger.info("[í…ìŠ¤íŠ¸]")
            logger.info(f"- ì¸ì‹ ê²°ê³¼: {text}")

        # ìƒ‰ìƒ ì •ë³´
        logger.info("[ìƒ‰ìƒ]")
        if isinstance(color_info, tuple):
            rgb, (group, specific) = color_info
            logger.info(f"- RGB ê°’: {rgb}")
            logger.info(f"- ìƒ‰ìƒ ê·¸ë£¹: {group}")
            logger.info(f"- êµ¬ì²´ì  ìƒ‰ìƒ: {specific}")

        # ëª¨ì–‘ ì •ë³´
        logger.info("[ëª¨ì–‘]")
        if shape_info and isinstance(shape_info, dict):
            predicted = shape_info.get('predicted_class')
            probs = shape_info.get('probabilities', {})
            logger.info(f"- ì˜ˆì¸¡ ê²°ê³¼: {predicted}")
            logger.info("- ì˜ˆì¸¡ í™•ë¥ :")
            for shape, prob in probs.items():
                logger.info(f"  - {shape}: {prob:.2%}")

        logger.info("="*50)

    def preprocess_image(self, image):
        """
        OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬

        Args:
            image (numpy.ndarray): BGR í˜•ì‹ì˜ ì…ë ¥ ì´ë¯¸ì§€

        Returns:
            numpy.ndarray: ì „ì²˜ë¦¬ëœ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
        """
        # BGRì—ì„œ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # CLAHE(Contrast Limited Adaptive Histogram Equalization) ì ìš©
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)

        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.GaussianBlur(enhanced, (3,3), 0)

        # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ì„ ëª…ë„ í–¥ìƒ
        gaussian_3 = cv2.GaussianBlur(denoised, (3,3), 2.0)
        unsharp_image = cv2.addWeighted(denoised, 1.5, gaussian_3, -0.5, 0)

        return unsharp_image

    def extract_text(self, image):
        """
        OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            image (numpy.ndarray): ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€

        Returns:
            list: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # OCR ìˆ˜í–‰
            ocr_result = self.ocr_reader.readtext(
                image,
                detail=1,
                paragraph=False,
                min_size=20,          # ìµœì†Œ í…ìŠ¤íŠ¸ í¬ê¸°
                contrast_ths=0.15,    # ëŒ€ë¹„ ì„ê³„ê°’
                adjust_contrast=0.4,  # ëŒ€ë¹„ ì¡°ì •
                text_threshold=0.6,   # í…ìŠ¤íŠ¸ ê°ì§€ ì„ê³„ê°’
                low_text=0.4,        # ë‚®ì€ í…ìŠ¤íŠ¸ ê°ë„
                link_threshold=0.4,   # í…ìŠ¤íŠ¸ ì—°ê²° ì„ê³„ê°’
                mag_ratio=1.2,       # í™•ëŒ€ ë¹„ìœ¨
                # ì•ŒíŒŒë²³ê³¼ ìˆ«ìë§Œ í—ˆìš©
                allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            )

            # ê²°ê³¼ í•„í„°ë§ ë° ì •ì œ
            filtered_result = []
            for (bbox, text, prob) in ocr_result:
                # íŠ¹ìˆ˜ë¬¸ì ì œê±°
                cleaned_text = re.sub(r'[^A-Z0-9]', '', text)
                if cleaned_text:  # ë¹ˆ í…ìŠ¤íŠ¸ ì œì™¸
                    filtered_result.append((cleaned_text, prob))

            # ë¡œê¹…
            texts = [text for text, _ in filtered_result]
            logger.info(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {texts}")

            return texts

        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []

    def extract_pill_color(self, image):
        """
        ì•Œì•½ì˜ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ

        Args:
            image (numpy.ndarray): BGR í˜•ì‹ì˜ ì…ë ¥ ì´ë¯¸ì§€

        Returns:
            tuple: (RGB ë¦¬ìŠ¤íŠ¸, (ìƒ‰ìƒ ê·¸ë£¹, êµ¬ì²´ì  ìƒ‰ìƒ))
        """
        try:
            # BGRì—ì„œ HSVë¡œ ë³€í™˜
            hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            pixels = hsv_image.reshape(-1, 3)

            # Gaussian Mixture Modelë¡œ ì£¼ìš” ìƒ‰ìƒ êµ°ì§‘í™”
            n_components = min(5, pixels.shape[0])
            gmm = GaussianMixture(
                n_components=n_components,
                random_state=42
            )
            gmm.fit(pixels)

            # ê°€ì¥ ë§ì€ êµ°ì§‘ì˜ í‰ê·  ìƒ‰ìƒ ì„ íƒ
            labels = gmm.predict(pixels)
            colors = gmm.means_.astype(int)
            counts = np.bincount(labels)

            # HSV to RGB ë³€í™˜
            dominant_color_hsv = colors[np.argmax(counts)]
            dominant_color_rgb = cv2.cvtColor(
                np.uint8([[dominant_color_hsv]]),
                cv2.COLOR_HSV2RGB
            )[0][0]

            # ê°€ì¥ ê°€ê¹Œìš´ ìƒ‰ìƒ ê·¸ë£¹ ì°¾ê¸°
            color_name = self.get_color_name(dominant_color_rgb)

            # ë¡œê¹…
            logger.info(f"ì¶”ì¶œëœ ìƒ‰ìƒ: RGB{dominant_color_rgb.tolist()}")
            logger.info(f"ìƒ‰ìƒ ë¶„ë¥˜: {color_name}")

            return dominant_color_rgb.tolist(), color_name

        except Exception as e:
            logger.error(f"ìƒ‰ìƒ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return [0, 0, 0], ("ì•Œ ìˆ˜ ì—†ìŒ", "ì•Œ ìˆ˜ ì—†ìŒ")

    def get_color_name(self, rgb_color):
        """
        RGB ê°’ì— ê°€ì¥ ê°€ê¹Œìš´ ìƒ‰ìƒ ì´ë¦„ ë°˜í™˜

        Args:
            rgb_color (list): RGB ìƒ‰ìƒê°’ ë¦¬ìŠ¤íŠ¸ [R, G, B]

        Returns:
            tuple: (ìƒ‰ìƒ ê·¸ë£¹ëª…, êµ¬ì²´ì  ìƒ‰ìƒëª…)
        """
        if rgb_color is None:
            return "ì•Œ ìˆ˜ ì—†ìŒ", "ì•Œ ìˆ˜ ì—†ìŒ"

        min_distance = float('inf')
        closest_group = 'ì•Œ ìˆ˜ ì—†ìŒ'
        specific_color = 'ì•Œ ìˆ˜ ì—†ìŒ'

        # ëª¨ë“  ìƒ‰ìƒ ê·¸ë£¹ì— ëŒ€í•´ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
        for group_name, colors in self.color_groups.items():
            for color_name, color in colors:
                distance = sum((a - b) ** 2 for a, b in zip(rgb_color, color)) ** 0.5
                if distance < min_distance:
                    min_distance = distance
                    closest_group = group_name
                    specific_color = color_name

        return closest_group, specific_color

    def process_image(self, image):
        """
        ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        ì•Œì•½ ê²€ì¶œ, íŠ¹ì„± ì¶”ì¶œ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            image (numpy.ndarray): BGR í˜•ì‹ì˜ ì…ë ¥ ì´ë¯¸ì§€

        Returns:
            list: ì²˜ë¦¬ëœ ì•Œì•½ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("\n" + "="*50)
        logger.info("[ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘]")
        logger.info(f"- ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")

        try:
            #################
            # 1. ëª¨ì–‘ ë¶„ë¥˜ #
            #################
            logger.info("\n[1ë‹¨ê³„: ëª¨ì–‘ ë¶„ë¥˜]")
            try:
                shape_result = self.shape_classifier.predict_shape(image)
                logger.info("[ì™„ë£Œ] ëª¨ì–‘ ë¶„ë¥˜ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"[ì˜¤ë¥˜] ëª¨ì–‘ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
                shape_result = None

            ##################
            # 2. ì•Œì•½ ê²€ì¶œ  #
            ##################
            logger.info("\n[2ë‹¨ê³„: ì•Œì•½ ê²€ì¶œ]")
            results = self.yolo_model(image)
            processed_results = []

            total_detections = len(results[0].boxes)
            logger.info(f"- ê²€ì¶œëœ ì•Œì•½ ìˆ˜: {total_detections}")

            # ê° ê²€ì¶œëœ ì•Œì•½ì— ëŒ€í•´ ì²˜ë¦¬
            for r in results:
                boxes = r.boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    conf = box.conf[0].item()
                    cls = int(box.cls[0].item())

                    logger.info("\n[ì•Œì•½ ë¶„ì„]")
                    logger.info(f"- ì‹ ë¢°ë„: {conf:.2%}")
                    logger.info(f"- ìœ„ì¹˜: ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})")

                    # ê²€ì¶œ ì˜ì—­ ìœ íš¨ì„± ê²€ì‚¬
                    if x2 <= x1 or y2 <= y1:
                        logger.warning("[ì£¼ì˜] ì˜ëª»ëœ ê²½ê³„ ìƒì ë¬´ì‹œ")
                        continue

                    # ì•Œì•½ ì´ë¯¸ì§€ ì¶”ì¶œ
                    pill_image = image[int(y1):int(y2), int(x1):int(x2)]
                    if pill_image.size == 0:
                        logger.warning("[ì£¼ì˜] ë¹ˆ ì´ë¯¸ì§€ ë¬´ì‹œ")
                        continue

                    try:
                        #####################
                        # 3. íŠ¹ì„± ì¶”ì¶œ     #
                        #####################
                        logger.info("\n[3ë‹¨ê³„: íŠ¹ì„± ì¶”ì¶œ]")

                        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                        preprocessed_image = self.preprocess_image(pill_image)

                        # ìƒ‰ìƒ ì¶”ì¶œ
                        logger.info("- ìƒ‰ìƒ ë¶„ì„ ì¤‘...")
                        dominant_color, color_name = self.extract_pill_color(pill_image)

                        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        logger.info("- í…ìŠ¤íŠ¸ ì¸ì‹ ì¤‘...")
                        text = self.extract_text(preprocessed_image)

                        # íŠ¹ì„± ë¡œê¹…
                        self.log_pill_features(text, (dominant_color, color_name), shape_result)

                        # ê²°ê³¼ ì €ì¥
                        processed_results.append({
                            'class': cls,
                            'confidence': conf,
                            'bbox': [x1, y1, x2, y2],
                            'text': text,
                            'color': {
                                'rgb': dominant_color,
                                'name': color_name[0],
                                'specific': color_name[1]
                            },
                            'shape': shape_result if shape_result else {
                                'predicted_class': 'ì•Œ ìˆ˜ ì—†ìŒ',
                                'probabilities': {}
                            }
                        })

                    except Exception as e:
                        logger.error(f"[ì˜¤ë¥˜] ì•Œì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        continue

            ##################
            # 4. ê²°ê³¼ ë°˜í™˜  #
            ##################
            logger.info("\n[4ë‹¨ê³„: ì²˜ë¦¬ ì™„ë£Œ]")
            logger.info(f"[ì™„ë£Œ] ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì•Œì•½: {len(processed_results)}ê°œ")
            logger.info("="*50 + "\n")

            return processed_results

        except Exception as e:
            logger.error(f"[ì˜¤ë¥˜] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            return []
####################
# Flask Routes     #
####################

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
model = PillRecognitionModel()

@app.route('/process_image', methods=['POST'])
@log_request_response
def process_image():
    """
    ì´ë¯¸ì§€ ì²˜ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
    ì…ë ¥: base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
    ì¶œë ¥: ê²€ì¶œëœ ì•Œì•½ë“¤ì˜ íŠ¹ì„± ì •ë³´
    
    Returns:
        tuple: (JSON ì‘ë‹µ, ìƒíƒœ ì½”ë“œ)
    """
    # ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    try:
        ##################
        # ì…ë ¥ê°’ ê²€ì¦   #
        ##################
        if 'image' not in request.json:
            logger.error("âš  ì´ë¯¸ì§€ ë°ì´í„° ëˆ„ë½")
            return jsonify({
                'error': 'ì´ë¯¸ì§€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400

        ###################
        # ì´ë¯¸ì§€ ë””ì½”ë”©  #
        ###################
        try:
            # base64 ë””ì½”ë”©
            image_data = base64.b64decode(request.json['image'])
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            nparr = np.frombuffer(image_data, np.uint8)
            # OpenCV ì´ë¯¸ì§€ë¡œ ë””ì½”ë”©
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if image is None:
                raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

        except Exception as e:
            logger.error(f"âš  ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {str(e)}")
            return jsonify({
                'error': 'ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤.'
            }), 400

        ###################
        # ì´ë¯¸ì§€ ì²˜ë¦¬    #
        ###################
        results = model.process_image(image)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        
        # ì‘ë‹µ ìƒì„±
        response_data = {
            'results': results,
            'processing_time': processing_time
        }
        
        logger.info(f"[ì™„ë£Œ] ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ ì†Œìš”")
        return jsonify(response_data), 200

    except Exception as e:
        logger.error(f"âš  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(traceback.format_exc())
        return jsonify({
            'error': str(e)
        }), 500

####################
# Main Execution  #
####################

if __name__ == '__main__':
    try:
        # ì‹œì‘ ë°°ë„ˆ ì¶œë ¥
        logger.info("\n" + "="*60)
        logger.info("[ì‹œì‘] ì•Œì•½ ì¸ì‹ ì„œë²„ ì‹œì‘")  # ğŸš€ ì´ëª¨ì§€ ì œê±°
        logger.info("="*60)
        
        # ì„œë²„ ì •ë³´ ì¶œë ¥
        logger.info("\n[ì„œë²„ ì •ë³´]")
        logger.info(f"- ì£¼ì†Œ: http://{PUBLIC_IP}:{MODEL_SERVER_PORT}")
        logger.info(f"- GPU ì‚¬ìš©: {'ê°€ëŠ¥' if torch.cuda.is_available() else 'ë¶ˆê°€ëŠ¥'}")
        if torch.cuda.is_available():
            logger.info(f"- GPU ì •ë³´: {torch.cuda.get_device_name(0)}")
        logger.info(f"- ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        
        # ëª¨ë¸ ê²½ë¡œ í™•ì¸
        logger.info("\n[ëª¨ë¸ ê²½ë¡œ]")
        logger.info(f"- YOLO: {YOLO_MODEL_PATH}")
        logger.info(f"- VGG: {VGG_MODEL_PATH}")  
        logger.info(f"- OCR: {OCR_MODEL_PATH}")  
        
        logger.info("\n[ì„œë²„ ì‹œì‘ ì¤‘...]")
        logger.info("="*60 + "\n")
        
        # Flask ì„œë²„ ì‹œì‘
        app.run(
            host='0.0.0.0',
            port=MODEL_SERVER_PORT,
            debug=False
        )
        
    except Exception as e:
        logger.error("\n[ì˜¤ë¥˜] ì„œë²„ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ!")  
        logger.error(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
        logger.error(traceback.format_exc())
        raise
